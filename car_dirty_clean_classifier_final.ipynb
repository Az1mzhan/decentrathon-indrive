{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6153e1da",
      "metadata": {
        "id": "6153e1da"
      },
      "source": [
        "\n",
        "# Dirt Segmentation → Clean/Dirty Classification (PyTorch, Gradio)\n",
        "\n",
        "This notebook implements the **cleanliness** part of our methodological framework:\n",
        "\n",
        "- Loads your **COCO (segmentation)** dataset (uses only the `dirty` category to build masks).\n",
        "- Trains a **lightweight U-Net** (pure PyTorch) for **dirt segmentation**.\n",
        "- Converts the predicted mask into an **image-level clean/dirty** decision by thresholding the dirt-area fraction.\n",
        "- Includes **single‑image inference** helpers and an optional **Gradio demo**.\n",
        "\n",
        "> Tip: Keep **offline augmentations out** of validation/test to avoid leakage. Add on‑the‑fly augmentation only in the training dataset if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "Hw5VcjE1QaFp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw5VcjE1QaFp",
        "outputId": "fce5c60b-f9b3-4938-8944-59b9ff1f4231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4YCGY4t9s9G3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YCGY4t9s9G3",
        "outputId": "2553bd99-3e60-4b5f-d399-2f76a4f8e7e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.8.0+cu126 | CUDA: True\n"
          ]
        }
      ],
      "source": [
        "# %% [code] 1 - Setup: GPU & packages\n",
        "\n",
        "import os, sys, json, math, random, zipfile, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageOps\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import cv2\n",
        "import gradio as gr\n",
        "\n",
        "random.seed(13)\n",
        "np.random.seed(13)\n",
        "torch.manual_seed(13)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(13)\n",
        "\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96a6d34",
      "metadata": {
        "id": "c96a6d34"
      },
      "source": [
        "\n",
        "## Configure dataset path\n",
        "\n",
        "The notebook expects a **Roboflow-style COCO segmentation** export:\n",
        "\n",
        "```\n",
        "dataset_root/\n",
        "  train/  _annotations.coco.json  <images...>\n",
        "  valid/  _annotations.coco.json  <images...>\n",
        "  test/   _annotations.coco.json  <images...>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7f4ab143",
      "metadata": {
        "id": "7f4ab143"
      },
      "outputs": [],
      "source": [
        "# %% [code] 2 - Config & Paths\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/decentrathon_dataset\")  # will be auto-detected after unzip if needed\n",
        "\n",
        "SIZE = 384\n",
        "BATCH = 2\n",
        "EPOCHS = 20\n",
        "\n",
        "# thresholds (can be recalibrated later)\n",
        "IMG_W = 0.7\n",
        "CLEAN_W = 1.0\n",
        "MASK_THR_DEFAULT  = 0.7\n",
        "CLEAN_THR_DEFAULT = 0.12\n",
        "MIN_BLOB_DEFAULT = 0.02\n",
        "DEFAULT_MASK_THR  = 0.80\n",
        "\n",
        "Path(\"checkpoints\").mkdir(exist_ok=True, parents=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "asF7sEu1pqbF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asF7sEu1pqbF",
        "outputId": "0efffc2f-aa3d-46ca-b8ce-c68c2b62c794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: images=200 | annotations=236\n",
            "valid: images=42 | annotations=86\n",
            "test: images=27 | annotations=60\n",
            "DATA_ROOT: /content/drive/MyDrive/decentrathon_dataset\n"
          ]
        }
      ],
      "source": [
        "# Basic structure & path checks per split\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    split_dir = DATA_ROOT / split\n",
        "    assert split_dir.exists(), f\"Missing split folder: {split_dir}\"\n",
        "    ann_path = split_dir / '_annotations.coco.json'\n",
        "    assert ann_path.exists(), f\"Missing COCO annotations: {ann_path}\"\n",
        "\n",
        "    data = json.loads(ann_path.read_text())\n",
        "    uses_prefix = any(\n",
        "        '/' in im.get('file_name', '') and im['file_name'].split('/')[0] in {'train','valid','test'}\n",
        "        for im in data.get('images', [])[:10]\n",
        "    )\n",
        "\n",
        "    # Resolve a sample image path to catch path-style mismatches\n",
        "    if data.get('images'):\n",
        "        sample = data['images'][0]['file_name']\n",
        "        # style A: \"train/xxx.jpg\" lives under DATA_ROOT\n",
        "        p_a = DATA_ROOT / sample if uses_prefix else None\n",
        "        # style B: \"xxx.jpg\" lives directly under split dir\n",
        "        p_b = split_dir / Path(sample).name\n",
        "\n",
        "        if uses_prefix:\n",
        "            assert p_a.exists() or p_b.exists(), f\"[{split}] Example image not found: tried {p_a} and {p_b}\"\n",
        "        else:\n",
        "            assert p_b.exists() or (DATA_ROOT / sample).exists(), f\"[{split}] Example image not found: tried {p_b} and {DATA_ROOT/sample}\"\n",
        "\n",
        "    print(f\"{split}: images={len(data.get('images', []))} | annotations={len(data.get('annotations', []))}\")\n",
        "\n",
        "print(\"DATA_ROOT:\", DATA_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "zCfKdugcprhe",
      "metadata": {
        "id": "zCfKdugcprhe"
      },
      "outputs": [],
      "source": [
        "# %% [code] 5 - Geometry & mask utilities\n",
        "def _denorm_if_needed(flat_xy, w, h):\n",
        "    if not flat_xy:\n",
        "        return flat_xy\n",
        "    mx, mn = max(flat_xy), min(flat_xy)\n",
        "    # If coords in [0..1] range, scale to pixels\n",
        "    if 0.0 <= mn and mx <= 1.5:\n",
        "        out = []\n",
        "        for i, v in enumerate(flat_xy):\n",
        "            out.append(v * (w if (i % 2) == 0 else h))\n",
        "        return out\n",
        "    return flat_xy\n",
        "\n",
        "def polygons_to_mask(polygons, height, width):\n",
        "    mask = Image.new(\"L\", (width, height), 0)\n",
        "    draw = ImageDraw.Draw(mask)\n",
        "    if isinstance(polygons, dict) and \"counts\" in polygons:\n",
        "        return np.zeros((height, width), dtype=np.uint8)  # ignore RLE\n",
        "    if isinstance(polygons, list) and len(polygons) > 0:\n",
        "        polys = polygons if isinstance(polygons[0], (list, tuple)) else [polygons]\n",
        "        for poly in polys:\n",
        "            if len(poly) >= 6:\n",
        "                flat = _denorm_if_needed(list(poly), width, height)\n",
        "                pts = [(flat[i], flat[i+1]) for i in range(0, len(flat), 2)]\n",
        "                if len(pts) >= 3:\n",
        "                    draw.polygon(pts, outline=1, fill=1)\n",
        "    return np.array(mask, dtype=np.uint8)\n",
        "\n",
        "def letterbox(img: Image.Image, size=512, fill=128):\n",
        "    w, h = img.size\n",
        "    s = size\n",
        "    scale = min(s / w, s / h)\n",
        "    nw, nh = int(round(w * scale)), int(round(h * scale))\n",
        "    img = img.resize((nw, nh), Image.Resampling.BILINEAR)\n",
        "    canvas = Image.new(\"RGB\", (s, s), (fill, fill, fill))\n",
        "    pad = ((s - nw) // 2, (s - nh) // 2)\n",
        "    canvas.paste(img, pad)\n",
        "    return canvas, pad, (nw, nh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "gYEi8G6apvCW",
      "metadata": {
        "id": "gYEi8G6apvCW"
      },
      "outputs": [],
      "source": [
        "# %% [code] 6 - Dataset\n",
        "class DirtCocoSemDataset(Dataset):\n",
        "    def __init__(self, root: Path, split: str, size=512, augment=False):\n",
        "        self.root = Path(root)/split\n",
        "        self.size = size\n",
        "        self.augment = augment\n",
        "        data = json.loads((self.root/\"_annotations.coco.json\").read_text())\n",
        "        self.images = {im['id']: im for im in data['images']}\n",
        "        self.anns_by_img = {}\n",
        "        for a in data.get('annotations', []):\n",
        "            self.anns_by_img.setdefault(a['image_id'], []).append(a)\n",
        "        self.cat_ok = {c['id']: any(k in c['name'].lower() for k in ['dirt','mud','grime'])\n",
        "                       for c in data.get('categories', [])}\n",
        "        self.list = list(self.images.keys())\n",
        "\n",
        "    def __len__(self): return len(self.list)\n",
        "\n",
        "    def _load_img(self, info):\n",
        "        fn = info['file_name']\n",
        "        p = (self.root/fn) if \"/\" not in fn else (self.root.parent/fn)\n",
        "        if not p.exists():\n",
        "            p = self.root/Path(fn).name\n",
        "        return Image.open(p).convert(\"RGB\")\n",
        "\n",
        "    def _mask_for_img(self, img_id, H, W):\n",
        "        mask = np.zeros((H, W), dtype=np.uint8)\n",
        "        for a in self.anns_by_img.get(img_id, []):\n",
        "            if not self.cat_ok.get(a.get('category_id'), False):\n",
        "                continue\n",
        "            seg = a.get('segmentation', [])\n",
        "            mask |= polygons_to_mask(seg, H, W)\n",
        "        return mask  # all-zero => clean\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.list[idx]\n",
        "        info = self.images[img_id]\n",
        "        im = self._load_img(info)\n",
        "        W, H = info.get('width', im.size[0]), info.get('height', im.size[1])\n",
        "        m = self._mask_for_img(img_id, H, W)\n",
        "\n",
        "        lb_img, (px, py), (nw, nh) = letterbox(im, self.size)\n",
        "        mask_img = Image.fromarray(m).resize((nw, nh), Image.Resampling.NEAREST)\n",
        "        lb_mask = Image.new(\"L\", (self.size, self.size), 0)\n",
        "        lb_mask.paste(mask_img, (px, py))\n",
        "\n",
        "        if self.augment:\n",
        "            if random.random() < 0.5:\n",
        "                lb_img = ImageOps.mirror(lb_img); lb_mask = ImageOps.mirror(lb_mask)\n",
        "            if random.random() < 0.2:\n",
        "                lb_img = ImageOps.autocontrast(lb_img)\n",
        "\n",
        "        x = TF.to_tensor(lb_img)\n",
        "        y = torch.from_numpy(np.array(lb_mask)).float()\n",
        "        y = (y > 0).float()\n",
        "        y_img = (y.max() > 0).long()\n",
        "        return x, y, y_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "jQel0GOkzwLG",
      "metadata": {
        "id": "jQel0GOkzwLG"
      },
      "outputs": [],
      "source": [
        "# %% [code] 8 - Model & loss\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_c, out_c, 3, 1, 1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_c, out_c, 3, 1, 1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class UNetSmall(nn.Module):\n",
        "    \"\"\"\n",
        "    width: base channel count. width=32 matches your old model.\n",
        "           width=16 halves channels (much lower memory).\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch=3, out_ch=1, width=32):\n",
        "        super().__init__()\n",
        "        c1, c2, c3, cb = width, width*2, width*4, width*8\n",
        "\n",
        "        self.d1 = DoubleConv(in_ch, c1); self.p1 = nn.MaxPool2d(2)\n",
        "        self.d2 = DoubleConv(c1, c2);    self.p2 = nn.MaxPool2d(2)\n",
        "        self.d3 = DoubleConv(c2, c3);    self.p3 = nn.MaxPool2d(2)\n",
        "        self.b  = DoubleConv(c3, cb)\n",
        "\n",
        "        self.u3  = nn.ConvTranspose2d(cb, c3, 2, 2); self.dc3 = DoubleConv(c3 + c3, c3)\n",
        "        self.u2  = nn.ConvTranspose2d(c3, c2, 2, 2); self.dc2 = DoubleConv(c2 + c2, c2)\n",
        "        self.u1  = nn.ConvTranspose2d(c2, c1, 2, 2); self.dc1 = DoubleConv(c1 + c1, c1)\n",
        "        self.out = nn.Conv2d(c1, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c1 = self.d1(x)\n",
        "        c2 = self.d2(self.p1(c1))\n",
        "        c3 = self.d3(self.p2(c2))\n",
        "        b  = self.b(self.p3(c3))\n",
        "\n",
        "        x  = self.u3(b); x = self.dc3(torch.cat([x, c3], 1))\n",
        "        x  = self.u2(x); x = self.dc2(torch.cat([x, c2], 1))\n",
        "        x  = self.u1(x); x = self.dc1(torch.cat([x, c1], 1))\n",
        "        return self.out(x)\n",
        "\n",
        "def dice_loss(logits, target, eps=1e-6):\n",
        "    probs = torch.sigmoid(logits)\n",
        "    num = 2 * (probs * target).sum() + eps\n",
        "    den = probs.sum() + target.sum() + eps\n",
        "    return 1 - num / den\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "bTm8CBRSpwDj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTm8CBRSpwDj",
        "outputId": "91bc1576-8f35-443d-ed03-71492d02d9ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 42, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# %% [code] 9 - DataLoaders\n",
        "train_ds = DirtCocoSemDataset(DATA_ROOT, \"train\", SIZE, augment=True)\n",
        "valid_ds = DirtCocoSemDataset(DATA_ROOT, \"valid\", SIZE, augment=False)\n",
        "test_ds  = DirtCocoSemDataset(DATA_ROOT, \"test\",  SIZE, augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_ds, batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "len(train_ds), len(valid_ds), len(test_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "X37gQ5WapxeY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X37gQ5WapxeY",
        "outputId": "af7d2d85-ed62-4510-9255-797cba84d188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated pos_weight ≈ 2.85\n"
          ]
        }
      ],
      "source": [
        "# %% [code] 10 - Losses, optimizer, metrics\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNetSmall(width=16).to(device)\n",
        "\n",
        "def estimate_pos_weight(loader, max_batches=100):\n",
        "    pos = tot = 0\n",
        "    for b, (_, y, _) in enumerate(loader):\n",
        "        y = y.unsqueeze(1).float()\n",
        "        pos += y.sum().item()\n",
        "        tot += y.numel()\n",
        "        if b+1 >= max_batches: break\n",
        "    p = max(1e-6, pos / tot)\n",
        "    return max(1.0, (1-p)/p)\n",
        "\n",
        "LR = 3e-4\n",
        "POS_WEIGHT = estimate_pos_weight(train_loader)\n",
        "print(f\"Estimated pos_weight ≈ {POS_WEIGHT:.2f}\")\n",
        "opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "sch  = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=10, eta_min=LR*0.2)\n",
        "\n",
        "bce_seg = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([POS_WEIGHT], device=device))\n",
        "bce_img = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def remove_small(predm: torch.Tensor, min_frac=0.003):\n",
        "    # predm: [B,1,H,W] bool. Morphological opening-ish with pooling to kill tiny blobs.\n",
        "    b,_,h,w = predm.shape\n",
        "    k = int(((h*w*min_frac)**0.5)//2*2 + 1)   # odd kernel size\n",
        "    x = predm.float()\n",
        "    x = F.max_pool2d(x, k, 1, k//2)\n",
        "    x = 1 - F.max_pool2d(1-x, k, 1, k//2)\n",
        "    return (x>0.5)\n",
        "\n",
        "def tversky_loss(logits, target, alpha=0.35, beta=0.65, gamma=1.2, eps=1e-6):\n",
        "    p = torch.sigmoid(logits)\n",
        "    tp = (p*target).sum()\n",
        "    fp = (p*(1-target)).sum()\n",
        "    fn = ((1-p)*target).sum()\n",
        "    tversky = (tp + eps) / (tp + alpha*fn + beta*fp + eps)\n",
        "    return (1.0 - tversky).pow(gamma)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_metrics(model, loader, mask_thr=MASK_THR_DEFAULT, clean_thr=CLEAN_THR_DEFAULT, min_blob=MIN_BLOB_DEFAULT):\n",
        "    model.eval()\n",
        "    inter_all = union_all = 0.0\n",
        "    tp=tn=fp=fn = 0.0\n",
        "    ious_pos = []\n",
        "    clean_total = clean_fp = 0\n",
        "\n",
        "    for x, y, y_img in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device).unsqueeze(1).float()\n",
        "        y_bool = (y > 0.5).bool()\n",
        "\n",
        "        logits = model(x)\n",
        "        prob   = torch.sigmoid(logits)            # [B,1,H,W]\n",
        "\n",
        "        # 1) threshold -> boolean mask\n",
        "        predm  = (prob > mask_thr)                # bool [B,1,H,W]\n",
        "\n",
        "        # 2) optional speckle clean-up\n",
        "        predm  = remove_small(predm, min_frac=0.002)\n",
        "\n",
        "        # global IoU\n",
        "        inter_all += (predm & y_bool).sum().item()\n",
        "        union_all += (predm | y_bool).sum().item()\n",
        "\n",
        "        # per-positive-image IoU and clean-FPR\n",
        "        bs = y.shape[0]\n",
        "        for i in range(bs):\n",
        "            if y_bool[i].any():\n",
        "                inter = (predm[i] & y_bool[i]).sum().item()\n",
        "                union = (predm[i] | y_bool[i]).sum().item()\n",
        "                ious_pos.append(inter / (union + 1e-9))\n",
        "            else:\n",
        "                clean_total += 1\n",
        "                clean_fp   += int(predm[i].any())\n",
        "\n",
        "        # image-level clean/dirty\n",
        "        frac   = predm.float().mean(dim=(2,3)).squeeze(1)  # fraction of positives per image\n",
        "        yhat   = (frac >= clean_thr)\n",
        "        y_true = y_img.to(device).view(-1).bool()\n",
        "\n",
        "        tp += ( yhat &  y_true).sum().item()\n",
        "        tn += (~yhat & ~y_true).sum().item()\n",
        "        fp += ( yhat & ~y_true).sum().item()\n",
        "        fn += (~yhat &  y_true).sum().item()\n",
        "\n",
        "    iou_all  = inter_all / max(1.0, union_all)\n",
        "    iou_pos  = float(sum(ious_pos) / max(1, len(ious_pos)))\n",
        "    clean_fpr = clean_fp / max(1, clean_total)\n",
        "    acc = (tp+tn) / max(1.0, tp+tn+fp+fn)\n",
        "    return iou_all, iou_pos, clean_fpr, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0HRZn8pvpy1m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HRZn8pvpy1m",
        "outputId": "54fb3025-4f49-44dd-9a16-9c65415de5ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1312930603.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | loss=1.300 | IoU_all=0.364 | IoU_pos=0.391 | cleanFPR=1.000 | acc=0.762\n",
            "  ↳ saved: checkpoints/unet_dirt_best.pth\n",
            "Epoch 2/20 | loss=1.228 | IoU_all=0.346 | IoU_pos=0.371 | cleanFPR=1.000 | acc=0.643\n",
            "Epoch 3/20 | loss=1.207 | IoU_all=0.246 | IoU_pos=0.253 | cleanFPR=1.000 | acc=0.524\n",
            "Epoch 4/20 | loss=1.189 | IoU_all=0.478 | IoU_pos=0.486 | cleanFPR=1.000 | acc=0.857\n",
            "  ↳ saved: checkpoints/unet_dirt_best.pth\n",
            "Epoch 5/20 | loss=1.194 | IoU_all=0.468 | IoU_pos=0.493 | cleanFPR=1.000 | acc=0.833\n",
            "Epoch 6/20 | loss=1.123 | IoU_all=0.501 | IoU_pos=0.537 | cleanFPR=1.000 | acc=0.762\n",
            "  ↳ saved: checkpoints/unet_dirt_best.pth\n",
            "Epoch 7/20 | loss=1.135 | IoU_all=0.518 | IoU_pos=0.543 | cleanFPR=1.000 | acc=0.786\n",
            "  ↳ saved: checkpoints/unet_dirt_best.pth\n",
            "Epoch 8/20 | loss=1.131 | IoU_all=0.354 | IoU_pos=0.338 | cleanFPR=0.800 | acc=0.667\n",
            "Epoch 9/20 | loss=1.121 | IoU_all=0.537 | IoU_pos=0.568 | cleanFPR=1.000 | acc=0.786\n",
            "  ↳ saved: checkpoints/unet_dirt_best.pth\n",
            "Epoch 10/20 | loss=1.132 | IoU_all=0.552 | IoU_pos=0.572 | cleanFPR=1.000 | acc=0.810\n",
            "  ↳ saved: checkpoints/unet_dirt_best.pth\n",
            "Epoch 11/20 | loss=1.074 | IoU_all=0.542 | IoU_pos=0.560 | cleanFPR=1.000 | acc=0.810\n",
            "Epoch 12/20 | loss=1.077 | IoU_all=0.519 | IoU_pos=0.544 | cleanFPR=1.000 | acc=0.786\n",
            "Epoch 13/20 | loss=1.075 | IoU_all=0.526 | IoU_pos=0.514 | cleanFPR=1.000 | acc=0.833\n",
            "Epoch 14/20 | loss=1.091 | IoU_all=0.597 | IoU_pos=0.602 | cleanFPR=1.000 | acc=0.857\n",
            "  ↳ saved: checkpoints/unet_dirt_best.pth\n",
            "Epoch 15/20 | loss=1.080 | IoU_all=0.520 | IoU_pos=0.532 | cleanFPR=1.000 | acc=0.810\n",
            "Epoch 16/20 | loss=1.037 | IoU_all=0.370 | IoU_pos=0.459 | cleanFPR=1.000 | acc=0.762\n",
            "Epoch 17/20 | loss=1.063 | IoU_all=0.583 | IoU_pos=0.645 | cleanFPR=1.000 | acc=0.762\n",
            "Epoch 18/20 | loss=1.052 | IoU_all=0.551 | IoU_pos=0.570 | cleanFPR=1.000 | acc=0.810\n",
            "Epoch 19/20 | loss=1.071 | IoU_all=0.577 | IoU_pos=0.597 | cleanFPR=1.000 | acc=0.786\n",
            "Epoch 20/20 | loss=1.054 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.690\n",
            "Best: (0.5973549369349117, 0.8571428571428571)\n"
          ]
        }
      ],
      "source": [
        "# %% [code] 11 - Training\n",
        "from contextlib import nullcontext\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "autocast_ctx = (lambda: torch.autocast('cuda', dtype=torch.float16)) if torch.cuda.is_available() else nullcontext\n",
        "\n",
        "WARMUP_EPOCHS = 5  # try 5–8 if you want to pretrain pure segmentation\n",
        "ACCUM_STEPS = 1\n",
        "\n",
        "best = (0.0, 0.0)\n",
        "CKPT = \"checkpoints/unet_dirt_best.pth\"\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "\n",
        "    for step, (x, y, y_img) in enumerate(train_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device).unsqueeze(1).float()\n",
        "        y_img = y_img.to(device).float().unsqueeze(1)\n",
        "\n",
        "        with autocast_ctx():\n",
        "            logits   = model(x)\n",
        "\n",
        "            seg_loss = 0.5*bce_seg(logits, y) + 0.5*tversky_loss(logits, y, alpha=0.9, beta=0.1)\n",
        "\n",
        "            img_logit = logits.mean(dim=(2,3))          # [B,1] logits for image-level\n",
        "            img_loss  = bce_img(img_logit, y_img)\n",
        "\n",
        "            # extra: penalize area ABOVE clean threshold for clean images only\n",
        "            prob      = torch.sigmoid(logits)\n",
        "            area      = prob.mean(dim=(2,3), keepdim=True)             # [B,1]\n",
        "            over      = (area - CLEAN_THR_DEFAULT).clamp(min=0)        # > 0 only if too big\n",
        "            clean_pen = ((1 - y_img) * over).mean()\n",
        "\n",
        "            loss = seg_loss + IMG_W*img_loss + CLEAN_W*clean_pen\n",
        "\n",
        "        scaler.scale(loss/ACCUM_STEPS).backward()\n",
        "        if (step+1) % ACCUM_STEPS == 0:\n",
        "            scaler.step(opt); scaler.update()\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        total += loss.item()\n",
        "\n",
        "    sch.step()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    iou_all, iou_pos, clean_fpr, acc = eval_metrics(\n",
        "        model, valid_loader,\n",
        "        mask_thr=MASK_THR_DEFAULT,\n",
        "        clean_thr=CLEAN_THR_DEFAULT,\n",
        "        min_blob=MIN_BLOB_DEFAULT\n",
        "    )\n",
        "\n",
        "    print(f\"Epoch {ep}/{EPOCHS} | loss={total/len(train_loader):.3f} | \"\n",
        "          f\"IoU_all={iou_all:.3f} | IoU_pos={iou_pos:.3f} | cleanFPR={clean_fpr:.3f} | acc={acc:.3f}\")\n",
        "\n",
        "    if iou_all>best[0] or (iou_all==best[0] and acc>best[1]):\n",
        "        best = (iou_all, acc)\n",
        "        torch.save({\"model\": model.state_dict(), \"size\": SIZE}, CKPT)\n",
        "        print(\"  ↳ saved:\", CKPT)\n",
        "\n",
        "print(\"Best:\", best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "rQ8Bh1WnA12M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ8Bh1WnA12M",
        "outputId": "6e2c9659-bcf0-4b10-eafb-cfafd325c946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask=0.65 | clean_thr=0.650 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.650 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.650 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.650 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.650 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.700 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.700 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.700 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.700 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.700 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.750 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.750 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.750 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.750 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.750 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.800 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.800 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.800 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.800 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.65 | clean_thr=0.800 | IoU_all=0.348 | IoU_pos=0.329 | cleanFPR=0.900 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.650 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.650 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.650 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.650 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.650 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.700 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.700 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.700 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.700 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.700 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.750 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.750 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.750 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.750 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.750 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.800 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.800 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.800 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.800 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.70 | clean_thr=0.800 | IoU_all=0.337 | IoU_pos=0.318 | cleanFPR=0.800 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.650 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.650 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.650 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.650 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.650 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.700 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.700 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.700 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.700 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.700 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.750 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.750 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.750 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.750 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.750 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.800 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.800 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.800 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.800 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.75 | clean_thr=0.800 | IoU_all=0.323 | IoU_pos=0.303 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.650 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.650 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.650 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.650 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.650 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.700 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.700 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.700 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.700 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.700 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.750 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.750 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.750 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.750 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.750 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.800 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.800 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.800 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.800 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n",
            "mask=0.80 | clean_thr=0.800 | IoU_all=0.303 | IoU_pos=0.280 | cleanFPR=0.500 | acc=0.238\n"
          ]
        }
      ],
      "source": [
        "# %% [code] 12 - Threshold sweep\n",
        "for mt in [0.65, 0.70, 0.75, 0.80]:\n",
        "    for ct in [0.65, 0.70, 0.75, 0.80]:\n",
        "      for mb in [0.12, 0.14, 0.16, 0.18, 0.20]:\n",
        "        i_all, i_pos, fpr, acc = eval_metrics(\n",
        "            model, valid_loader, mask_thr=mt, clean_thr=ct, min_blob=MIN_BLOB_DEFAULT\n",
        "        )\n",
        "        print(f\"mask={mt:.2f} | clean_thr={ct:.3f} | IoU_all={i_all:.3f} | \"\n",
        "              f\"IoU_pos={i_pos:.3f} | cleanFPR={fpr:.3f} | acc={acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "I34vWREDw2D4",
      "metadata": {
        "id": "I34vWREDw2D4"
      },
      "outputs": [],
      "source": [
        "# %% [code] 13 - Inference utilities\n",
        "def area_filter(mask_np: np.ndarray, min_pixels: int):\n",
        "    n, labels, stats, _ = cv2.connectedComponentsWithStats(mask_np.astype('uint8'), connectivity=8)\n",
        "    keep = np.zeros_like(mask_np, dtype=np.uint8)\n",
        "    for i in range(1, n):\n",
        "        if stats[i, cv2.CC_STAT_AREA] >= min_pixels:\n",
        "            keep[labels == i] = 1\n",
        "    return keep\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_image(pil_im: Image.Image, mask_thr=DEFAULT_MASK_THR, clean_thr=CLEAN_THR_DEFAULT):\n",
        "    model.eval()\n",
        "    img, pad, _ = letterbox(pil_im.convert(\"RGB\"), SIZE)\n",
        "    x = TF.to_tensor(img).unsqueeze(0).to(device)\n",
        "    prob = torch.sigmoid(model(x))[0,0].cpu().numpy()\n",
        "    pred = (prob > mask_thr).astype(np.uint8)\n",
        "    pred = area_filter(pred, int(0.001 * pred.size))   # drop tiny blobs (~0.1% of image)\n",
        "    dirt_frac = float(pred.mean())\n",
        "    label = \"DIRTY\" if dirt_frac >= clean_thr else \"CLEAN\"\n",
        "\n",
        "    sem = Image.fromarray((pred*255).astype(np.uint8))\n",
        "    ov  = img.convert(\"RGBA\")\n",
        "    red = ImageOps.colorize(sem, black=(0,0,0), white=(255,0,0)).convert(\"RGBA\")\n",
        "    out = Image.alpha_composite(ov, red).convert(\"RGB\")\n",
        "    return out, f\"dirt_fraction={dirt_frac:.3f} → {label}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "NE7yQmmjw3hM",
      "metadata": {
        "id": "NE7yQmmjw3hM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c318abd-eeb4-4b6a-c2c6-5b53b8b4b6a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: checkpoints/unet_dirt_best.pth\n"
          ]
        }
      ],
      "source": [
        "# %% [code] 14 - Load checkpoint\n",
        "CKPT = \"checkpoints/unet_dirt_best.pth\"\n",
        "state = torch.load(CKPT, map_location=device)\n",
        "model.load_state_dict(state[\"model\"])\n",
        "model.eval()\n",
        "print(\"Loaded:\", CKPT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "CDY6I88Yw6KY",
      "metadata": {
        "id": "CDY6I88Yw6KY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "e84f8d82-c708-409c-b46c-1ccc13362bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a538010c8202051b2d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a538010c8202051b2d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# %% [code] 15 - Gradio demo\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### Dirt segmentation + image-level CLEAN/DIRTY\")\n",
        "    with gr.Row():\n",
        "        inp = gr.Image(type=\"pil\", label=\"Upload or paste a photo\")\n",
        "        out_img = gr.Image(label=\"Mask overlay\")\n",
        "    with gr.Row():\n",
        "        mask_thr  = gr.Slider(0.1, 0.95, value=DEFAULT_MASK_THR, step=0.01, label=\"Mask threshold\")\n",
        "        clean_thr = gr.Slider(0.0, 0.4,  value=CLEAN_THR_DEFAULT, step=0.01, label=\"Clean/Dirty threshold (fraction)\")\n",
        "    out_txt = gr.Textbox(label=\"Result\")\n",
        "    btn = gr.Button(\"Submit\")\n",
        "    btn.click(predict_image, [inp, mask_thr, clean_thr], [out_img, out_txt])\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}